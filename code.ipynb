{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCtiLheWdLTS"
      },
      "source": [
        "# Global Tweet Sentiment Analysis - Mood of the World"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl2PbgOKdUia"
      },
      "source": [
        "# Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsXufA_7XySO"
      },
      "outputs": [],
      "source": [
        "!pip install tweepy textblob plotly pandas numpy wordcloud matplotlib seaborn python-dotenv --quiet\n",
        "!python -m textblob.download_corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwbnEPFwdbDO"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtEaBILWX8nv"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "import json\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "pyo.init_notebook_mode(connected=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOq4Gvjydn4g"
      },
      "source": [
        "# Twitter API Configuration\n",
        "## Note : get API from https://developer.twitter.com/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfCHLwrwd_Mn"
      },
      "outputs": [],
      "source": [
        "class TwitterConfig:\n",
        "    def __init__(self):\n",
        "        # Replace with your actual API credentials\n",
        "        # Note : Use Paid Key if you use free key then the limit will be reached during data Preparation\n",
        "        self.API_KEY = \"YOUR_API_KEY\"\n",
        "        self.API_SECRET = \"YOUR_API_SECRET\"\n",
        "        self.ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"\n",
        "        self.ACCESS_TOKEN_SECRET = \"YOUR_ACCESS_TOKEN_SECRET\"\n",
        "        self.BEARER_TOKEN = \"YOUR_BEARER_TOKEN\"\n",
        "\n",
        "    def get_api_v1(self):\n",
        "        \"\"\"Get Twitter API v1.1 client\"\"\"\n",
        "        auth = tweepy.OAuthHandler(self.API_KEY, self.API_SECRET)\n",
        "        auth.set_access_token(self.ACCESS_TOKEN, self.ACCESS_TOKEN_SECRET)\n",
        "        return tweepy.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "    def get_api_v2(self):\n",
        "        \"\"\"Get Twitter API v2 client\"\"\"\n",
        "        return tweepy.Client(\n",
        "            bearer_token=self.BEARER_TOKEN,\n",
        "            consumer_key=self.API_KEY,\n",
        "            consumer_secret=self.API_SECRET,\n",
        "            access_token=self.ACCESS_TOKEN,\n",
        "            access_token_secret=self.ACCESS_TOKEN_SECRET,\n",
        "            wait_on_rate_limit=True\n",
        "        )\n",
        "config = TwitterConfig()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkgYKLtdeLNj"
      },
      "source": [
        "# Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZa1gmgheKoL"
      },
      "outputs": [],
      "source": [
        "class GlobalTweetCollector:\n",
        "    def __init__(self, api_v1, api_v2):\n",
        "        self.api_v1 = api_v1\n",
        "        self.api_v2 = api_v2\n",
        "        self.tweets_data = []\n",
        "\n",
        "    def clean_tweet(self, text):\n",
        "        \"\"\"Clean tweet text for better sentiment analysis\"\"\"\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "        text = ' '.join(text.split())\n",
        "        return text.strip()\n",
        "\n",
        "    def get_sentiment(self, text):\n",
        "        \"\"\"Analyze sentiment using TextBlob\"\"\"\n",
        "        try:\n",
        "            blob = TextBlob(text)\n",
        "            polarity = blob.sentiment.polarity\n",
        "            subjectivity = blob.sentiment.subjectivity\n",
        "            if polarity > 0.1:\n",
        "                sentiment = 'Positive'\n",
        "            elif polarity < -0.1:\n",
        "                sentiment = 'Negative'\n",
        "            else:\n",
        "                sentiment = 'Neutral'\n",
        "\n",
        "            return {\n",
        "                'sentiment': sentiment,\n",
        "                'polarity': polarity,\n",
        "                'subjectivity': subjectivity\n",
        "            }\n",
        "        except:\n",
        "            return {\n",
        "                'sentiment': 'Neutral',\n",
        "                'polarity': 0.0,\n",
        "                'subjectivity': 0.0\n",
        "            }\n",
        "\n",
        "    def collect_global_tweets(self, keywords=None, count=1000):\n",
        "        \"\"\"Collect tweets from around the world\"\"\"\n",
        "        if keywords is None:\n",
        "            keywords = [\n",
        "                \"good morning\", \"how are you\", \"feeling\", \"mood\", \"happy\",\n",
        "                \"sad\", \"excited\", \"worried\", \"grateful\", \"blessed\",\n",
        "                \"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\",\n",
        "                \"weekend\", \"today\", \"life\", \"work\", \"family\"\n",
        "            ]\n",
        "\n",
        "        print(f\"Starting global tweet collection...\")\n",
        "\n",
        "        for keyword in keywords:\n",
        "            try:\n",
        "                print(f\"Searching for: '{keyword}'\")\n",
        "                tweets = tweepy.Paginator(\n",
        "                    self.api_v2.search_recent_tweets,\n",
        "                    query=f\"{keyword} -is:retweet lang:en\",\n",
        "                    tweet_fields=['created_at', 'author_id', 'public_metrics', 'geo'],\n",
        "                    max_results=100,\n",
        "                    limit=10\n",
        "                ).flatten(limit=count // len(keywords))\n",
        "\n",
        "                for tweet in tweets:\n",
        "                    if tweet.text:\n",
        "                        cleaned_text = self.clean_tweet(tweet.text)\n",
        "                        if len(cleaned_text) > 10:\n",
        "                            sentiment_data = self.get_sentiment(cleaned_text)\n",
        "\n",
        "                            tweet_data = {\n",
        "                                'id': tweet.id,\n",
        "                                'text': cleaned_text,\n",
        "                                'original_text': tweet.text,\n",
        "                                'created_at': tweet.created_at,\n",
        "                                'author_id': tweet.author_id,\n",
        "                                'keyword': keyword,\n",
        "                                'sentiment': sentiment_data['sentiment'],\n",
        "                                'polarity': sentiment_data['polarity'],\n",
        "                                'subjectivity': sentiment_data['subjectivity'],\n",
        "                                'retweet_count': tweet.public_metrics['retweet_count'] if tweet.public_metrics else 0,\n",
        "                                'like_count': tweet.public_metrics['like_count'] if tweet.public_metrics else 0,\n",
        "                            }\n",
        "\n",
        "                            self.tweets_data.append(tweet_data)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error collecting tweets for '{keyword}': {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"Collected {len(self.tweets_data)} tweets total\")\n",
        "        return pd.DataFrame(self.tweets_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI1zPxCvfL4a"
      },
      "source": [
        "# Initialize APIs and Collect Data or Sample Data for Demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNBAgeuWfMAq"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    api_v1 = config.get_api_v1()\n",
        "    api_v2 = config.get_api_v2()\n",
        "\n",
        "    print(\"Testing Twitter API connection...\")\n",
        "    me = api_v1.verify_credentials()\n",
        "    if me:\n",
        "        print(f\"Connected as: @{me.screen_name}\")\n",
        "    else:\n",
        "        print(\"API connection failed.\")\n",
        "    collector = GlobalTweetCollector(api_v1, api_v2)\n",
        "    df_tweets = collector.collect_global_tweets(count=2000)\n",
        "\n",
        "    if len(df_tweets) > 0:\n",
        "        print(f\"Dataset shape: {df_tweets.shape}\")\n",
        "        print(\"\\n Dataset info:\")\n",
        "        print(df_tweets.info())\n",
        "        print(f\"\\n Sentiment distribution:\")\n",
        "        print(df_tweets['sentiment'].value_counts())\n",
        "    else:\n",
        "        print(\"No tweets collected. Check your API credentials.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {str(e)}\")\n",
        "\n",
        "    print(\"\\n Creating sample data for demonstration...\")\n",
        "    sample_data = {\n",
        "        'text': [\n",
        "            'Having a great day today!',\n",
        "            'Feeling a bit down lately',\n",
        "            'Just another normal Monday',\n",
        "            'So excited for the weekend!',\n",
        "            'Work is really stressing me out',\n",
        "            'Grateful for my family and friends',\n",
        "            'Weather is perfect today',\n",
        "            'This week has been challenging',\n",
        "            'Looking forward to vacation',\n",
        "            'Love spending time with loved ones'\n",
        "        ] * 50,\n",
        "        'sentiment': ['Positive', 'Negative', 'Neutral', 'Positive', 'Negative'] * 100,\n",
        "        'polarity': np.random.normal(0, 0.3, 500),\n",
        "        'subjectivity': np.random.uniform(0, 1, 500),\n",
        "        'created_at': pd.date_range(start='2024-01-01', periods=500, freq='H'),\n",
        "        'keyword': np.random.choice(['mood', 'feeling', 'today', 'happy', 'work'], 500)\n",
        "    }\n",
        "    df_tweets = pd.DataFrame(sample_data)\n",
        "    print(f\"Sample dataset created with {len(df_tweets)} tweets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Hh1nSsgG0j"
      },
      "source": [
        "# Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfAEAFcbgG73"
      },
      "outputs": [],
      "source": [
        "class SentimentAnalyzer:\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "        self.prepare_data()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Prepare data for analysis\"\"\"\n",
        "        if 'created_at' in self.df.columns:\n",
        "            self.df['created_at'] = pd.to_datetime(self.df['created_at'])\n",
        "            self.df['hour'] = self.df['created_at'].dt.hour\n",
        "            self.df['day_of_week'] = self.df['created_at'].dt.day_name()\n",
        "            self.df['date'] = self.df['created_at'].dt.date\n",
        "\n",
        "    def get_sentiment_summary(self):\n",
        "        \"\"\"Get overall sentiment statistics\"\"\"\n",
        "        total_tweets = len(self.df)\n",
        "        sentiment_counts = self.df['sentiment'].value_counts()\n",
        "\n",
        "        summary = {\n",
        "            'total_tweets': total_tweets,\n",
        "            'positive_pct': (sentiment_counts.get('Positive', 0) / total_tweets) * 100,\n",
        "            'negative_pct': (sentiment_counts.get('Negative', 0) / total_tweets) * 100,\n",
        "            'neutral_pct': (sentiment_counts.get('Neutral', 0) / total_tweets) * 100,\n",
        "            'avg_polarity': self.df['polarity'].mean(),\n",
        "            'avg_subjectivity': self.df['subjectivity'].mean()\n",
        "        }\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def get_hourly_sentiment(self):\n",
        "        \"\"\"Analyze sentiment by hour of day\"\"\"\n",
        "        hourly_sentiment = self.df.groupby(['hour', 'sentiment']).size().unstack(fill_value=0)\n",
        "        hourly_polarity = self.df.groupby('hour')['polarity'].mean()\n",
        "\n",
        "        return hourly_sentiment, hourly_polarity\n",
        "\n",
        "    def get_daily_sentiment(self):\n",
        "        \"\"\"Analyze sentiment by day of week\"\"\"\n",
        "        daily_sentiment = self.df.groupby(['day_of_week', 'sentiment']).size().unstack(fill_value=0)\n",
        "        daily_polarity = self.df.groupby('day_of_week')['polarity'].mean()\n",
        "\n",
        "        return daily_sentiment, daily_polarity\n",
        "\n",
        "    def get_keyword_sentiment(self):\n",
        "        \"\"\"Analyze sentiment by keyword\"\"\"\n",
        "        if 'keyword' in self.df.columns:\n",
        "            keyword_sentiment = self.df.groupby(['keyword', 'sentiment']).size().unstack(fill_value=0)\n",
        "            keyword_polarity = self.df.groupby('keyword')['polarity'].mean().sort_values(ascending=False)\n",
        "            return keyword_sentiment, keyword_polarity\n",
        "        return None, None\n",
        "\n",
        "analyzer = SentimentAnalyzer(df_tweets)\n",
        "summary = analyzer.get_sentiment_summary()\n",
        "\n",
        "print(\"Mood of the World SUMMARY\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Total Tweets Analyzed: {summary['total_tweets']:,}\")\n",
        "print(f\"Positive Sentiment: {summary['positive_pct']:.1f}%\")\n",
        "print(f\"Negative Sentiment: {summary['negative_pct']:.1f}%\")\n",
        "print(f\"Neutral Sentiment: {summary['neutral_pct']:.1f}%\")\n",
        "print(f\"Average Polarity: {summary['avg_polarity']:.3f}\")\n",
        "print(f\"Average Subjectivity: {summary['avg_subjectivity']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-NNAAQegqqE"
      },
      "source": [
        "# Create Interactive Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRY4TI6pgqyC"
      },
      "outputs": [],
      "source": [
        "class SentimentVisualizer:\n",
        "    def __init__(self, df, analyzer):\n",
        "        self.df = df\n",
        "        self.analyzer = analyzer\n",
        "\n",
        "    def create_sentiment_overview(self):\n",
        "        \"\"\"Create overview dashboard\"\"\"\n",
        "        summary = self.analyzer.get_sentiment_summary()\n",
        "\n",
        "        # Create subplots\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=('Sentiment Distribution', 'Polarity Distribution',\n",
        "                          'Subjectivity vs Polarity', 'Sentiment Over Time'),\n",
        "            specs=[[{\"type\": \"pie\"}, {\"type\": \"histogram\"}],\n",
        "                   [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]]\n",
        "        )\n",
        "\n",
        "        # Sentiment pie chart\n",
        "        sentiment_counts = self.df['sentiment'].value_counts()\n",
        "        colors = ['#2E86AB', '#A23B72', '#F18F01']\n",
        "        fig.add_trace(\n",
        "            go.Pie(labels=sentiment_counts.index, values=sentiment_counts.values,\n",
        "                   marker_colors=colors, name=\"Sentiment\"),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # Polarity histogram\n",
        "        fig.add_trace(\n",
        "            go.Histogram(x=self.df['polarity'], nbinsx=30, name=\"Polarity\",\n",
        "                        marker_color='#2E86AB', opacity=0.7),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "        # Subjectivity vs Polarity scatter\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=self.df['subjectivity'], y=self.df['polarity'],\n",
        "                      mode='markers', name=\"Tweets\",\n",
        "                      marker=dict(color=self.df['polarity'], colorscale='RdYlBu',\n",
        "                                size=5, opacity=0.6),\n",
        "                      text=self.df['text'].str[:100] + '...',\n",
        "                      hovertemplate='<b>Subjectivity:</b> %{x:.2f}<br>' +\n",
        "                                  '<b>Polarity:</b> %{y:.2f}<br>' +\n",
        "                                  '<b>Text:</b> %{text}<extra></extra>'),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # Sentiment over time (if date available)\n",
        "        if 'created_at' in self.df.columns:\n",
        "            hourly_data = self.df.groupby([self.df['created_at'].dt.hour, 'sentiment']).size().unstack(fill_value=0)\n",
        "\n",
        "            for sentiment in ['Positive', 'Negative', 'Neutral']:\n",
        "                if sentiment in hourly_data.columns:\n",
        "                    fig.add_trace(\n",
        "                        go.Scatter(x=hourly_data.index, y=hourly_data[sentiment],\n",
        "                                 mode='lines+markers', name=f\"{sentiment} Tweets\",\n",
        "                                 line=dict(width=2)),\n",
        "                        row=2, col=2\n",
        "                    )\n",
        "\n",
        "        fig.update_layout(\n",
        "            title_text=\"üåç Global Mood Analysis Dashboard\",\n",
        "            title_x=0.5,\n",
        "            height=800,\n",
        "            showlegend=True,\n",
        "            template=\"plotly_white\"\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_hourly_heatmap(self):\n",
        "        \"\"\"Create hourly sentiment heatmap\"\"\"\n",
        "        hourly_sentiment, hourly_polarity = self.analyzer.get_hourly_sentiment()\n",
        "\n",
        "        # Calculate percentages\n",
        "        hourly_pct = hourly_sentiment.div(hourly_sentiment.sum(axis=1), axis=0) * 100\n",
        "\n",
        "        fig = go.Figure()\n",
        "\n",
        "        # Add heatmap for each sentiment\n",
        "        sentiments = ['Positive', 'Neutral', 'Negative']\n",
        "        colors = ['Greens', 'Greys', 'Reds']\n",
        "\n",
        "        for i, (sentiment, colorscale) in enumerate(zip(sentiments, colors)):\n",
        "            if sentiment in hourly_pct.columns:\n",
        "                visible = True if i == 0 else False\n",
        "                fig.add_trace(\n",
        "                    go.Heatmap(\n",
        "                        z=[hourly_pct[sentiment].values],\n",
        "                        x=hourly_pct.index,\n",
        "                        y=[sentiment],\n",
        "                        colorscale=colorscale,\n",
        "                        name=sentiment,\n",
        "                        visible=visible,\n",
        "                        hovertemplate=f'<b>Hour:</b> %{{x}}<br><b>{sentiment}:</b> %{{z:.1f}}%<extra></extra>'\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        # Add buttons for different sentiments\n",
        "        buttons = []\n",
        "        for i, sentiment in enumerate(sentiments):\n",
        "            if sentiment in hourly_pct.columns:\n",
        "                visibility = [False] * len(sentiments)\n",
        "                visibility[i] = True\n",
        "                buttons.append(\n",
        "                    dict(\n",
        "                        method=\"update\",\n",
        "                        args=[{\"visible\": visibility}],\n",
        "                        label=sentiment\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=\"üìÖ Hourly Sentiment Distribution\",\n",
        "            xaxis_title=\"Hour of Day\",\n",
        "            updatemenus=[\n",
        "                dict(\n",
        "                    type=\"buttons\",\n",
        "                    direction=\"right\",\n",
        "                    x=0.7,\n",
        "                    y=1.15,\n",
        "                    buttons=buttons\n",
        "                )\n",
        "            ],\n",
        "            height=400,\n",
        "            template=\"plotly_white\"\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_world_mood_gauge(self):\n",
        "        \"\"\"Create a mood gauge for the world\"\"\"\n",
        "        summary = self.analyzer.get_sentiment_summary()\n",
        "        avg_polarity = summary['avg_polarity']\n",
        "\n",
        "        # Convert polarity to 0-100 scale\n",
        "        mood_score = ((avg_polarity + 1) / 2) * 100\n",
        "\n",
        "        fig = go.Figure(go.Indicator(\n",
        "            mode = \"gauge+number+delta\",\n",
        "            value = mood_score,\n",
        "            domain = {'x': [0, 1], 'y': [0, 1]},\n",
        "            title = {'text': \"üåç World Mood Score\"},\n",
        "            delta = {'reference': 50},\n",
        "            gauge = {\n",
        "                'axis': {'range': [None, 100]},\n",
        "                'bar': {'color': \"darkblue\"},\n",
        "                'steps': [\n",
        "                    {'range': [0, 25], 'color': \"lightgray\"},\n",
        "                    {'range': [25, 50], 'color': \"gray\"},\n",
        "                    {'range': [50, 75], 'color': \"lightgreen\"},\n",
        "                    {'range': [75, 100], 'color': \"green\"}\n",
        "                ],\n",
        "                'threshold': {\n",
        "                    'line': {'color': \"red\", 'width': 4},\n",
        "                    'thickness': 0.75,\n",
        "                    'value': 90\n",
        "                }\n",
        "            }\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            height=400,\n",
        "            template=\"plotly_white\",\n",
        "            annotations=[\n",
        "                dict(\n",
        "                    x=0.5, y=0.1,\n",
        "                    text=f\"Based on {summary['total_tweets']:,} tweets<br>\" +\n",
        "                         f\"Avg Polarity: {avg_polarity:.3f}\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=12)\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_keyword_sentiment_chart(self):\n",
        "        \"\"\"Create keyword sentiment analysis\"\"\"\n",
        "        keyword_sentiment, keyword_polarity = self.analyzer.get_keyword_sentiment()\n",
        "\n",
        "        if keyword_sentiment is not None:\n",
        "            fig = px.bar(\n",
        "                keyword_sentiment.reset_index(),\n",
        "                x='keyword',\n",
        "                y=['Positive', 'Neutral', 'Negative'],\n",
        "                title=\"üìù Sentiment by Keyword\",\n",
        "                labels={'value': 'Number of Tweets', 'keyword': 'Keywords'},\n",
        "                color_discrete_map={\n",
        "                    'Positive': '#2E86AB',\n",
        "                    'Neutral': '#A23B72',\n",
        "                    'Negative': '#F18F01'\n",
        "                }\n",
        "            )\n",
        "\n",
        "            fig.update_layout(\n",
        "                height=500,\n",
        "                template=\"plotly_white\",\n",
        "                xaxis_tickangle=-45\n",
        "            )\n",
        "\n",
        "            return fig\n",
        "        return None\n",
        "\n",
        "# Create visualizations\n",
        "visualizer = SentimentVisualizer(df_tweets, analyzer)\n",
        "print(\"Interactive Visualizations\")\n",
        "\n",
        "# Overview Dashboard\n",
        "overview_fig = visualizer.create_sentiment_overview()\n",
        "overview_fig.show()\n",
        "\n",
        "# Hourly Heatmap\n",
        "hourly_fig = visualizer.create_hourly_heatmap()\n",
        "hourly_fig.show()\n",
        "\n",
        "# World Mood Gauge\n",
        "gauge_fig = visualizer.create_world_mood_gauge()\n",
        "gauge_fig.show()\n",
        "\n",
        "# Keyword Sentiment Analysis\n",
        "keyword_fig = visualizer.create_keyword_sentiment_chart()\n",
        "if keyword_fig:\n",
        "    keyword_fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHDGcH3wnhG3"
      },
      "source": [
        "# Word Cloud Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bJ370Z6oyv-"
      },
      "outputs": [],
      "source": [
        "def create_sentiment_wordclouds(df):\n",
        "    \"\"\"Create word clouds for different sentiments\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    sentiments = ['Positive', 'Negative', 'Neutral']\n",
        "    colors = ['Greens', 'Reds', 'Blues']\n",
        "\n",
        "    for i, (sentiment, colormap) in enumerate(zip(sentiments, colors)):\n",
        "        sentiment_tweets = df[df['sentiment'] == sentiment]['text']\n",
        "\n",
        "        if len(sentiment_tweets) > 0:\n",
        "            text = ' '.join(sentiment_tweets.astype(str))\n",
        "\n",
        "            wordcloud = WordCloud(\n",
        "                width=400, height=300,\n",
        "                background_color='white',\n",
        "                colormap=colormap,\n",
        "                max_words=100,\n",
        "                relative_scaling=0.5,\n",
        "                random_state=42\n",
        "            ).generate(text)\n",
        "\n",
        "            axes[i].imshow(wordcloud, interpolation='bilinear')\n",
        "            axes[i].set_title(f'{sentiment} Tweets', fontsize=16, fontweight='bold')\n",
        "            axes[i].axis('off')\n",
        "        else:\n",
        "            axes[i].text(0.5, 0.5, f'No {sentiment} tweets',\n",
        "                        ha='center', va='center', transform=axes[i].transAxes)\n",
        "            axes[i].set_title(f'{sentiment} Tweets', fontsize=16, fontweight='bold')\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('‚òÅÔ∏è Word Clouds by Sentiment', fontsize=20, fontweight='bold', y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "# Generate word clouds\n",
        "create_sentiment_wordclouds(df_tweets)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NwbnEPFwdbDO",
        "IOq4Gvjydn4g",
        "MkgYKLtdeLNj",
        "aI1zPxCvfL4a",
        "-6Hh1nSsgG0j",
        "J-NNAAQegqqE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
