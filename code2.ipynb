{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NwbnEPFwdbDO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Global Tweet Sentiment Analysis - Mood of the World { Free API Version }"
      ],
      "metadata": {
        "id": "pCtiLheWdLTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Required Packages"
      ],
      "metadata": {
        "id": "Jl2PbgOKdUia"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsXufA_7XySO"
      },
      "outputs": [],
      "source": [
        "!pip install tweepy textblob plotly pandas numpy wordcloud matplotlib seaborn python-dotenv scikit-learn --quiet\n",
        "!python -m textblob.download_corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "NwbnEPFwdbDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "import json\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "pyo.init_notebook_mode(connected=True)"
      ],
      "metadata": {
        "id": "ZtEaBILWX8nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter API Configuration\n",
        "## Note : get API from https://developer.twitter.com/\n"
      ],
      "metadata": {
        "id": "IOq4Gvjydn4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwitterConfig:\n",
        "    def __init__(self):\n",
        "        # Replace with your actual API credentials\n",
        "        self.API_KEY = \"YOUR_API_KEY\"\n",
        "        self.API_SECRET = \"YOUR_API_SECRET\"\n",
        "        self.ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"\n",
        "        self.ACCESS_TOKEN_SECRET = \"YOUR_ACCESS_TOKEN_SECRET\"\n",
        "        self.BEARER_TOKEN = \"YOUR_BEARER_TOKEN\"\n",
        "\n",
        "        # Rate limit settings\n",
        "        self.FREE_TIER_MONTHLY_LIMIT = 100\n",
        "        self.DAILY_BUDGET = 10\n",
        "        self.BATCH_SIZE = 25\n",
        "        self.REQUEST_DELAY = 1.5\n",
        "\n",
        "    def get_api_v1(self):\n",
        "        \"\"\"Get Twitter API v1.1 client\"\"\"\n",
        "        auth = tweepy.OAuthHandler(self.API_KEY, self.API_SECRET)\n",
        "        auth.set_access_token(self.ACCESS_TOKEN, self.ACCESS_TOKEN_SECRET)\n",
        "        return tweepy.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "    def get_api_v2(self):\n",
        "        \"\"\"Get Twitter API v2 client\"\"\"\n",
        "        return tweepy.Client(\n",
        "            bearer_token=self.BEARER_TOKEN,\n",
        "            consumer_key=self.API_KEY,\n",
        "            consumer_secret=self.API_SECRET,\n",
        "            access_token=self.ACCESS_TOKEN,\n",
        "            access_token_secret=self.ACCESS_TOKEN_SECRET,\n",
        "            wait_on_rate_limit=True\n",
        "        )\n",
        "config = TwitterConfig()"
      ],
      "metadata": {
        "id": "zfCHLwrwd_Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection Via API or Sample Data for Demonstration"
      ],
      "metadata": {
        "id": "MkgYKLtdeLNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalTweetCollector:\n",
        "    def __init__(self, api_v1=None, api_v2=None):\n",
        "        self.api_v1 = api_v1\n",
        "        self.api_v2 = api_v2\n",
        "        self.tweets_data = []\n",
        "\n",
        "    def clean_tweet(self, text):\n",
        "        \"\"\"tweet cleaning\"\"\"\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]', '', text)\n",
        "        return text.strip()\n",
        "\n",
        "    def get_enhanced_sentiment(self, text):\n",
        "        \"\"\"sentiment analysis with confidence scores\"\"\"\n",
        "        try:\n",
        "            blob = TextBlob(text)\n",
        "            polarity = blob.sentiment.polarity\n",
        "            subjectivity = blob.sentiment.subjectivity\n",
        "            if polarity > 0.2:\n",
        "                sentiment = 'Positive'\n",
        "                confidence = abs(polarity)\n",
        "            elif polarity < -0.2:\n",
        "                sentiment = 'Negative'\n",
        "                confidence = abs(polarity)\n",
        "            else:\n",
        "                sentiment = 'Neutral'\n",
        "                confidence = 1 - abs(polarity)\n",
        "            emotion = self.detect_emotion(text.lower())\n",
        "\n",
        "            return {\n",
        "                'sentiment': sentiment,\n",
        "                'polarity': polarity,\n",
        "                'subjectivity': subjectivity,\n",
        "                'confidence': confidence,\n",
        "                'emotion': emotion,\n",
        "                'word_count': len(text.split())\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'sentiment': 'Neutral',\n",
        "                'polarity': 0.0,\n",
        "                'subjectivity': 0.0,\n",
        "                'confidence': 0.0,\n",
        "                'emotion': 'neutral',\n",
        "                'word_count': 0\n",
        "            }\n",
        "\n",
        "    def detect_emotion(self, text):\n",
        "        \"\"\"Detect basic emotions from text\"\"\"\n",
        "        emotion_keywords = {\n",
        "            'joy': ['happy', 'excited', 'great', 'wonderful', 'amazing', 'love', 'perfect'],\n",
        "            'sadness': ['sad', 'depressed', 'down', 'upset', 'disappointed', 'lonely'],\n",
        "            'anger': ['angry', 'mad', 'furious', 'annoyed', 'frustrated', 'hate'],\n",
        "            'fear': ['scared', 'afraid', 'worried', 'anxious', 'nervous', 'panic'],\n",
        "            'surprise': ['surprised', 'shocked', 'unexpected', 'wow', 'omg'],\n",
        "            'gratitude': ['grateful', 'thankful', 'blessed', 'appreciate', 'lucky']\n",
        "        }\n",
        "\n",
        "        emotion_scores = {}\n",
        "        for emotion, keywords in emotion_keywords.items():\n",
        "            score = sum(1 for keyword in keywords if keyword in text)\n",
        "            if score > 0:\n",
        "                emotion_scores[emotion] = score\n",
        "\n",
        "        if emotion_scores:\n",
        "            return max(emotion_scores, key=emotion_scores.get)\n",
        "        return 'neutral'\n",
        "\n",
        "    def collect_tweets_with_api(self, keywords=None, count=50):\n",
        "        \"\"\"Collect tweets using Twitter API\"\"\"\n",
        "        if not self.api_v2:\n",
        "            print(\"Twitter API not configured\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        if keywords is None:\n",
        "            keywords = [\"feeling good\", \"having a great day\", \"feeling down\", \"stressed out\", \"grateful today\"]\n",
        "\n",
        "        print(f\"Collecting tweets using Twitter API...\")\n",
        "        print(f\"Target: {count} tweets across {len(keywords)} keywords\")\n",
        "\n",
        "        tweets_per_keyword = max(1, count // len(keywords))\n",
        "\n",
        "        for i, keyword in enumerate(keywords):\n",
        "            if len(self.tweets_data) >= count:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                print(f\"Searching: '{keyword}' ({i+1}/{len(keywords)})\")\n",
        "\n",
        "                tweets = self.api_v2.search_recent_tweets(\n",
        "                    query=f'\"{keyword}\" -is:retweet lang:en',\n",
        "                    tweet_fields=['created_at', 'author_id', 'public_metrics', 'context_annotations'],\n",
        "                    max_results=min(tweets_per_keyword, 100)\n",
        "                )\n",
        "\n",
        "                if tweets.data:\n",
        "                    for tweet in tweets.data:\n",
        "                        if len(self.tweets_data) >= count:\n",
        "                            break\n",
        "\n",
        "                        cleaned_text = self.clean_tweet(tweet.text)\n",
        "                        if len(cleaned_text) > 15:\n",
        "                            sentiment_data = self.get_enhanced_sentiment(cleaned_text)\n",
        "\n",
        "                            tweet_data = {\n",
        "                                'id': tweet.id,\n",
        "                                'text': cleaned_text,\n",
        "                                'original_text': tweet.text,\n",
        "                                'created_at': tweet.created_at,\n",
        "                                'author_id': tweet.author_id,\n",
        "                                'keyword': keyword,\n",
        "                                'source': 'twitter_api',\n",
        "                                **sentiment_data,\n",
        "                                'retweet_count': tweet.public_metrics.get('retweet_count', 0) if tweet.public_metrics else 0,\n",
        "                                'like_count': tweet.public_metrics.get('like_count', 0) if tweet.public_metrics else 0,\n",
        "                            }\n",
        "\n",
        "                            self.tweets_data.append(tweet_data)\n",
        "\n",
        "                import time\n",
        "                time.sleep(config.REQUEST_DELAY)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error with '{keyword}': {str(e)}\")\n",
        "                if \"rate limit\" in str(e).lower():\n",
        "                    print(\"Rate limit reached - switching to sample data\")\n",
        "                    break\n",
        "\n",
        "        print(f\"Collected {len(self.tweets_data)} real tweets\")\n",
        "        return pd.DataFrame(self.tweets_data)\n",
        "\n",
        "    def generate_realistic_sample_data(self, size=1000):\n",
        "        \"\"\"Generate realistic sample data with patterns\"\"\"\n",
        "        print(f\" Generating {size} realistic sample tweets...\")\n",
        "\n",
        "        tweet_templates = {\n",
        "            'positive': [\n",
        "                \"Just had the most amazing coffee this morning! ☀️\",\n",
        "                \"Feeling incredibly grateful for my family today 💕\",\n",
        "                \"Beautiful sunset tonight, life is good! 🌅\",\n",
        "                \"Finally finished that project I've been working on! 🎉\",\n",
        "                \"Met up with old friends today, such a perfect day! 😊\",\n",
        "                \"Got some great news today, feeling so blessed! ✨\",\n",
        "                \"Nothing beats a good workout to start the day! 💪\",\n",
        "                \"Weekend vibes are hitting different today! 🌟\",\n",
        "                \"Sometimes the little things make me the happiest 💝\",\n",
        "                \"Accomplished so much today, feeling proud! 🏆\"\n",
        "            ],\n",
        "            'negative': [\n",
        "                \"Having one of those days where nothing goes right 😔\",\n",
        "                \"Really struggling to find motivation lately\",\n",
        "                \"Work has been incredibly stressful this week\",\n",
        "                \"Feeling overwhelmed with everything going on\",\n",
        "                \"Just need a break from all this chaos\",\n",
        "                \"When will things start looking up? 😞\",\n",
        "                \"Another sleepless night ahead of me\",\n",
        "                \"Can't seem to catch a break these days\",\n",
        "                \"Feeling disconnected from everyone lately\",\n",
        "                \"This weather is really getting me down\"\n",
        "            ],\n",
        "            'neutral': [\n",
        "                \"Just another typical Monday morning\",\n",
        "                \"Regular day at the office, nothing special\",\n",
        "                \"Weather looks okay for the weekend\",\n",
        "                \"Going through my usual routine today\",\n",
        "                \"Standard Tuesday, same as always\",\n",
        "                \"Just checking in, hope everyone's well\",\n",
        "                \"Another day, another dollar as they say\",\n",
        "                \"Normal evening at home tonight\",\n",
        "                \"Regular coffee meeting this afternoon\",\n",
        "                \"Just going with the flow today\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        emotions_dist = {'positive': 0.45, 'negative': 0.25, 'neutral': 0.30}\n",
        "        sample_data = []\n",
        "        end_date = datetime.now()\n",
        "        start_date = end_date - timedelta(days=7)\n",
        "        timestamps = pd.date_range(start=start_date, end=end_date, periods=size)\n",
        "\n",
        "        for i, timestamp in enumerate(timestamps):\n",
        "            hour = timestamp.hour\n",
        "            day_of_week = timestamp.weekday()\n",
        "\n",
        "            if 7 <= hour <= 10:\n",
        "                pos_boost = 0.15\n",
        "            elif 18 <= hour <= 21:\n",
        "                pos_boost = 0.10\n",
        "            elif 23 <= hour <= 2:\n",
        "                pos_boost = -0.20\n",
        "            elif day_of_week >= 5:\n",
        "                pos_boost = 0.12\n",
        "            else:\n",
        "                pos_boost = 0\n",
        "\n",
        "            adjusted_pos = min(0.7, emotions_dist['positive'] + pos_boost)\n",
        "            adjusted_neg = max(0.1, emotions_dist['negative'] - pos_boost/2)\n",
        "            adjusted_neu = 1 - adjusted_pos - adjusted_neg\n",
        "\n",
        "            sentiment_choice = np.random.choice(\n",
        "                ['positive', 'negative', 'neutral'],\n",
        "                p=[adjusted_pos, adjusted_neg, adjusted_neu]\n",
        "            )\n",
        "\n",
        "            template = np.random.choice(tweet_templates[sentiment_choice])\n",
        "\n",
        "            variations = {\n",
        "                'positive': ['!', ' 🙂', ' Today was good.', ' Feeling blessed.'],\n",
        "                'negative': ['...', ' 😕', ' Not my best day.', ' Hope tomorrow is better.'],\n",
        "                'neutral': ['.', ' Just saying.', ' That\\'s life.', ' Moving on.']\n",
        "            }\n",
        "\n",
        "            text = template + np.random.choice(variations[sentiment_choice])\n",
        "\n",
        "            sentiment_data = self.get_enhanced_sentiment(text)\n",
        "\n",
        "            if sentiment_choice == 'positive':\n",
        "                likes = np.random.poisson(8)\n",
        "                retweets = np.random.poisson(2)\n",
        "            elif sentiment_choice == 'negative':\n",
        "                likes = np.random.poisson(3)\n",
        "                retweets = np.random.poisson(1)\n",
        "            else:\n",
        "                likes = np.random.poisson(4)\n",
        "                retweets = np.random.poisson(1)\n",
        "\n",
        "            sample_data.append({\n",
        "                'id': f'sample_{i}',\n",
        "                'text': text,\n",
        "                'original_text': text,\n",
        "                'created_at': timestamp,\n",
        "                'author_id': f'user_{i % 100}',\n",
        "                'keyword': np.random.choice(['mood', 'feeling', 'day', 'life', 'today']),\n",
        "                'source': 'sample_data',\n",
        "                **sentiment_data,\n",
        "                'like_count': likes,\n",
        "                'retweet_count': retweets,\n",
        "            })\n",
        "\n",
        "        print(f\"Generated {len(sample_data)} realistic sample tweets\")\n",
        "        return pd.DataFrame(sample_data)"
      ],
      "metadata": {
        "id": "HZa1gmgheKoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize APIs and Collect Data"
      ],
      "metadata": {
        "id": "aI1zPxCvfL4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_data_collection():\n",
        "    \"\"\"Initialize data collection with fallback options\"\"\"\n",
        "    collector = GlobalTweetCollector()\n",
        "    df_final = pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        print(\"Attempting Twitter API connection...\")\n",
        "        api_v1 = config.get_api_v1()\n",
        "        api_v2 = config.get_api_v2()\n",
        "\n",
        "        me = api_v1.verify_credentials()\n",
        "        if me:\n",
        "            print(f\"Connected as: @{me.screen_name}\")\n",
        "            collector.api_v1 = api_v1\n",
        "            collector.api_v2 = api_v2\n",
        "\n",
        "            df_real = collector.collect_tweets_with_api(count=config.DAILY_BUDGET)\n",
        "            if len(df_real) > 0:\n",
        "                df_final = pd.concat([df_final, df_real], ignore_index=True)\n",
        "                print(f\"Added {len(df_real)} real tweets\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Twitter API issue: {str(e)[:100]}...\")\n",
        "        print(\"Continuing with sample data only\")\n",
        "\n",
        "    print(\"\\nGenerating comprehensive sample dataset...\")\n",
        "    df_sample = collector.generate_realistic_sample_data(1200)\n",
        "    df_final = pd.concat([df_final, df_sample], ignore_index=True)\n",
        "\n",
        "    df_final['created_at'] = pd.to_datetime(df_final['created_at'])\n",
        "    df_final['hour'] = df_final['created_at'].dt.hour\n",
        "    df_final['day_of_week'] = df_final['created_at'].dt.day_name()\n",
        "    df_final['date'] = df_final['created_at'].dt.date\n",
        "    df_final['is_weekend'] = df_final['created_at'].dt.weekday >= 5\n",
        "\n",
        "    print(f\"\\n Final dataset ready!\")\n",
        "    print(f\"Total tweets: {len(df_final):,}\")\n",
        "    print(f\"Real tweets: {len(df_final[df_final['source'] == 'twitter_api']):,}\")\n",
        "    print(f\"Sample tweets: {len(df_final[df_final['source'] == 'sample_data']):,}\")\n",
        "    print(f\"Date range: {df_final['created_at'].min().date()} to {df_final['created_at'].max().date()}\")\n",
        "\n",
        "    return df_final, collector\n",
        "\n",
        "df_tweets, collector = initialize_data_collection()"
      ],
      "metadata": {
        "id": "yNBAgeuWfMAq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}