{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NwbnEPFwdbDO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Global Tweet Sentiment Analysis - Mood of the World { HTML Report }"
      ],
      "metadata": {
        "id": "pCtiLheWdLTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Required Packages"
      ],
      "metadata": {
        "id": "Jl2PbgOKdUia"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsXufA_7XySO"
      },
      "outputs": [],
      "source": [
        "!pip install tweepy textblob plotly pandas numpy wordcloud matplotlib seaborn python-dotenv scikit-learn --quiet\n",
        "!python -m textblob.download_corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "NwbnEPFwdbDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "import random\n",
        "import json\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "pyo.init_notebook_mode(connected=True)\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"colab\"\n",
        "from plotly.offline import init_notebook_mode\n",
        "init_notebook_mode(connected=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZtEaBILWX8nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter API Configuration\n",
        "## Note : get API from https://developer.twitter.com/\n"
      ],
      "metadata": {
        "id": "IOq4Gvjydn4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwitterConfig:\n",
        "    def __init__(self):\n",
        "        # Replace with your actual API credentials\n",
        "        self.API_KEY = \"YOUR_API_KEY\"\n",
        "        self.API_SECRET = \"YOUR_API_SECRET\"\n",
        "        self.ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"\n",
        "        self.ACCESS_TOKEN_SECRET = \"YOUR_ACCESS_TOKEN_SECRET\"\n",
        "        self.BEARER_TOKEN = \"YOUR_BEARER_TOKEN\"\n",
        "\n",
        "        # Rate limit settings\n",
        "        self.FREE_TIER_MONTHLY_LIMIT = 100\n",
        "        self.DAILY_BUDGET = 10\n",
        "        self.BATCH_SIZE = 25\n",
        "        self.REQUEST_DELAY = 1.5\n",
        "\n",
        "    def get_api_v1(self):\n",
        "        \"\"\"Get Twitter API v1.1 client\"\"\"\n",
        "        auth = tweepy.OAuthHandler(self.API_KEY, self.API_SECRET)\n",
        "        auth.set_access_token(self.ACCESS_TOKEN, self.ACCESS_TOKEN_SECRET)\n",
        "        return tweepy.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "    def get_api_v2(self):\n",
        "        \"\"\"Get Twitter API v2 client\"\"\"\n",
        "        return tweepy.Client(\n",
        "            bearer_token=self.BEARER_TOKEN,\n",
        "            consumer_key=self.API_KEY,\n",
        "            consumer_secret=self.API_SECRET,\n",
        "            access_token=self.ACCESS_TOKEN,\n",
        "            access_token_secret=self.ACCESS_TOKEN_SECRET,\n",
        "            wait_on_rate_limit=True\n",
        "        )\n",
        "config = TwitterConfig()"
      ],
      "metadata": {
        "id": "zfCHLwrwd_Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection Via API or Sample Data for Demonstration"
      ],
      "metadata": {
        "id": "MkgYKLtdeLNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalTweetCollector:\n",
        "    def __init__(self, api_v1=None, api_v2=None):\n",
        "        self.api_v1 = api_v1\n",
        "        self.api_v2 = api_v2\n",
        "        self.tweets_data = []\n",
        "\n",
        "    def clean_tweet(self, text):\n",
        "        \"\"\"tweet cleaning\"\"\"\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]', '', text)\n",
        "        return text.strip()\n",
        "\n",
        "    def get_enhanced_sentiment(self, text):\n",
        "        \"\"\"sentiment analysis with confidence scores\"\"\"\n",
        "        try:\n",
        "            blob = TextBlob(text)\n",
        "            polarity = blob.sentiment.polarity\n",
        "            subjectivity = blob.sentiment.subjectivity\n",
        "            if polarity > 0.2:\n",
        "                sentiment = 'Positive'\n",
        "                confidence = abs(polarity)\n",
        "            elif polarity < -0.2:\n",
        "                sentiment = 'Negative'\n",
        "                confidence = abs(polarity)\n",
        "            else:\n",
        "                sentiment = 'Neutral'\n",
        "                confidence = 1 - abs(polarity)\n",
        "            emotion = self.detect_emotion(text.lower())\n",
        "\n",
        "            return {\n",
        "                'sentiment': sentiment,\n",
        "                'polarity': polarity,\n",
        "                'subjectivity': subjectivity,\n",
        "                'confidence': confidence,\n",
        "                'emotion': emotion,\n",
        "                'word_count': len(text.split())\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'sentiment': 'Neutral',\n",
        "                'polarity': 0.0,\n",
        "                'subjectivity': 0.0,\n",
        "                'confidence': 0.0,\n",
        "                'emotion': 'neutral',\n",
        "                'word_count': 0\n",
        "            }\n",
        "\n",
        "    def detect_emotion(self, text):\n",
        "        \"\"\"Detect basic emotions from text\"\"\"\n",
        "        emotion_keywords = {\n",
        "            'joy': ['happy', 'excited', 'great', 'wonderful', 'amazing', 'love', 'perfect'],\n",
        "            'sadness': ['sad', 'depressed', 'down', 'upset', 'disappointed', 'lonely'],\n",
        "            'anger': ['angry', 'mad', 'furious', 'annoyed', 'frustrated', 'hate'],\n",
        "            'fear': ['scared', 'afraid', 'worried', 'anxious', 'nervous', 'panic'],\n",
        "            'surprise': ['surprised', 'shocked', 'unexpected', 'wow', 'omg'],\n",
        "            'gratitude': ['grateful', 'thankful', 'blessed', 'appreciate', 'lucky']\n",
        "        }\n",
        "\n",
        "        emotion_scores = {}\n",
        "        for emotion, keywords in emotion_keywords.items():\n",
        "            score = sum(1 for keyword in keywords if keyword in text)\n",
        "            if score > 0:\n",
        "                emotion_scores[emotion] = score\n",
        "\n",
        "        if emotion_scores:\n",
        "            return max(emotion_scores, key=emotion_scores.get)\n",
        "        return 'neutral'\n",
        "\n",
        "    def collect_tweets_with_api(self, keywords=None, count=50):\n",
        "        \"\"\"Collect tweets using Twitter API\"\"\"\n",
        "        if not self.api_v2:\n",
        "            print(\"Twitter API not configured\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        if keywords is None:\n",
        "            keywords = [\"feeling good\", \"having a great day\", \"feeling down\", \"stressed out\", \"grateful today\"]\n",
        "\n",
        "        print(f\"Collecting tweets using Twitter API...\")\n",
        "        print(f\"Target: {count} tweets across {len(keywords)} keywords\")\n",
        "\n",
        "        tweets_per_keyword = max(1, count // len(keywords))\n",
        "\n",
        "        for i, keyword in enumerate(keywords):\n",
        "            if len(self.tweets_data) >= count:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                print(f\"Searching: '{keyword}' ({i+1}/{len(keywords)})\")\n",
        "\n",
        "                tweets = self.api_v2.search_recent_tweets(\n",
        "                    query=f'\"{keyword}\" -is:retweet lang:en',\n",
        "                    tweet_fields=['created_at', 'author_id', 'public_metrics', 'context_annotations'],\n",
        "                    max_results=min(tweets_per_keyword, 100)\n",
        "                )\n",
        "\n",
        "                if tweets.data:\n",
        "                    for tweet in tweets.data:\n",
        "                        if len(self.tweets_data) >= count:\n",
        "                            break\n",
        "\n",
        "                        cleaned_text = self.clean_tweet(tweet.text)\n",
        "                        if len(cleaned_text) > 15:\n",
        "                            sentiment_data = self.get_enhanced_sentiment(cleaned_text)\n",
        "\n",
        "                            tweet_data = {\n",
        "                                'id': tweet.id,\n",
        "                                'text': cleaned_text,\n",
        "                                'original_text': tweet.text,\n",
        "                                'created_at': tweet.created_at,\n",
        "                                'author_id': tweet.author_id,\n",
        "                                'keyword': keyword,\n",
        "                                'source': 'twitter_api',\n",
        "                                **sentiment_data,\n",
        "                                'retweet_count': tweet.public_metrics.get('retweet_count', 0) if tweet.public_metrics else 0,\n",
        "                                'like_count': tweet.public_metrics.get('like_count', 0) if tweet.public_metrics else 0,\n",
        "                            }\n",
        "\n",
        "                            self.tweets_data.append(tweet_data)\n",
        "\n",
        "                import time\n",
        "                time.sleep(config.REQUEST_DELAY)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error with '{keyword}': {str(e)}\")\n",
        "                if \"rate limit\" in str(e).lower():\n",
        "                    print(\"Rate limit reached - switching to sample data\")\n",
        "                    break\n",
        "\n",
        "        print(f\"Collected {len(self.tweets_data)} real tweets\")\n",
        "        return pd.DataFrame(self.tweets_data)\n",
        "\n",
        "    def generate_realistic_sample_data(self, size=1000):\n",
        "        \"\"\"Generate realistic sample data with patterns\"\"\"\n",
        "        print(f\" Generating {size} realistic sample tweets...\")\n",
        "\n",
        "        tweet_templates = {\n",
        "            'positive': [\n",
        "                \"Just had the most amazing coffee this morning! ☀️\",\n",
        "                \"Feeling incredibly grateful for my family today 💕\",\n",
        "                \"Beautiful sunset tonight, life is good! 🌅\",\n",
        "                \"Finally finished that project I've been working on! 🎉\",\n",
        "                \"Met up with old friends today, such a perfect day! 😊\",\n",
        "                \"Got some great news today, feeling so blessed! ✨\",\n",
        "                \"Nothing beats a good workout to start the day! 💪\",\n",
        "                \"Weekend vibes are hitting different today! 🌟\",\n",
        "                \"Sometimes the little things make me the happiest 💝\",\n",
        "                \"Accomplished so much today, feeling proud! 🏆\"\n",
        "            ],\n",
        "            'negative': [\n",
        "                \"Having one of those days where nothing goes right 😔\",\n",
        "                \"Really struggling to find motivation lately\",\n",
        "                \"Work has been incredibly stressful this week\",\n",
        "                \"Feeling overwhelmed with everything going on\",\n",
        "                \"Just need a break from all this chaos\",\n",
        "                \"When will things start looking up? 😞\",\n",
        "                \"Another sleepless night ahead of me\",\n",
        "                \"Can't seem to catch a break these days\",\n",
        "                \"Feeling disconnected from everyone lately\",\n",
        "                \"This weather is really getting me down\"\n",
        "            ],\n",
        "            'neutral': [\n",
        "                \"Just another typical Monday morning\",\n",
        "                \"Regular day at the office, nothing special\",\n",
        "                \"Weather looks okay for the weekend\",\n",
        "                \"Going through my usual routine today\",\n",
        "                \"Standard Tuesday, same as always\",\n",
        "                \"Just checking in, hope everyone's well\",\n",
        "                \"Another day, another dollar as they say\",\n",
        "                \"Normal evening at home tonight\",\n",
        "                \"Regular coffee meeting this afternoon\",\n",
        "                \"Just going with the flow today\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        emotions_dist = {'positive': 0.45, 'negative': 0.25, 'neutral': 0.30}\n",
        "        sample_data = []\n",
        "        end_date = datetime.now()\n",
        "        start_date = end_date - timedelta(days=7)\n",
        "        timestamps = pd.date_range(start=start_date, end=end_date, periods=size)\n",
        "\n",
        "        for i, timestamp in enumerate(timestamps):\n",
        "            hour = timestamp.hour\n",
        "            day_of_week = timestamp.weekday()\n",
        "\n",
        "            if 7 <= hour <= 10:\n",
        "                pos_boost = 0.15\n",
        "            elif 18 <= hour <= 21:\n",
        "                pos_boost = 0.10\n",
        "            elif 23 <= hour <= 2:\n",
        "                pos_boost = -0.20\n",
        "            elif day_of_week >= 5:\n",
        "                pos_boost = 0.12\n",
        "            else:\n",
        "                pos_boost = 0\n",
        "\n",
        "            adjusted_pos = min(0.7, emotions_dist['positive'] + pos_boost)\n",
        "            adjusted_neg = max(0.1, emotions_dist['negative'] - pos_boost/2)\n",
        "            adjusted_neu = 1 - adjusted_pos - adjusted_neg\n",
        "\n",
        "            sentiment_choice = np.random.choice(\n",
        "                ['positive', 'negative', 'neutral'],\n",
        "                p=[adjusted_pos, adjusted_neg, adjusted_neu]\n",
        "            )\n",
        "\n",
        "            template = np.random.choice(tweet_templates[sentiment_choice])\n",
        "\n",
        "            variations = {\n",
        "                'positive': ['!', ' 🙂', ' Today was good.', ' Feeling blessed.'],\n",
        "                'negative': ['...', ' 😕', ' Not my best day.', ' Hope tomorrow is better.'],\n",
        "                'neutral': ['.', ' Just saying.', ' That\\'s life.', ' Moving on.']\n",
        "            }\n",
        "\n",
        "            text = template + np.random.choice(variations[sentiment_choice])\n",
        "\n",
        "            sentiment_data = self.get_enhanced_sentiment(text)\n",
        "\n",
        "            if sentiment_choice == 'positive':\n",
        "                likes = np.random.poisson(8)\n",
        "                retweets = np.random.poisson(2)\n",
        "            elif sentiment_choice == 'negative':\n",
        "                likes = np.random.poisson(3)\n",
        "                retweets = np.random.poisson(1)\n",
        "            else:\n",
        "                likes = np.random.poisson(4)\n",
        "                retweets = np.random.poisson(1)\n",
        "\n",
        "            sample_data.append({\n",
        "                'id': f'sample_{i}',\n",
        "                'text': text,\n",
        "                'original_text': text,\n",
        "                'created_at': timestamp,\n",
        "                'author_id': f'user_{i % 100}',\n",
        "                'keyword': np.random.choice(['mood', 'feeling', 'day', 'life', 'today']),\n",
        "                'source': 'sample_data',\n",
        "                **sentiment_data,\n",
        "                'like_count': likes,\n",
        "                'retweet_count': retweets,\n",
        "            })\n",
        "\n",
        "        print(f\"Generated {len(sample_data)} realistic sample tweets\")\n",
        "        return pd.DataFrame(sample_data)"
      ],
      "metadata": {
        "id": "HZa1gmgheKoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize APIs and Collect Data"
      ],
      "metadata": {
        "id": "aI1zPxCvfL4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_data_collection():\n",
        "    \"\"\"Initialize data collection with fallback options\"\"\"\n",
        "    collector = GlobalTweetCollector()\n",
        "    df_final = pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        print(\"Attempting Twitter API connection...\")\n",
        "        api_v1 = config.get_api_v1()\n",
        "        api_v2 = config.get_api_v2()\n",
        "\n",
        "        me = api_v1.verify_credentials()\n",
        "        if me:\n",
        "            print(f\"Connected as: @{me.screen_name}\")\n",
        "            collector.api_v1 = api_v1\n",
        "            collector.api_v2 = api_v2\n",
        "\n",
        "            df_real = collector.collect_tweets_with_api(count=config.DAILY_BUDGET)\n",
        "            if len(df_real) > 0:\n",
        "                df_final = pd.concat([df_final, df_real], ignore_index=True)\n",
        "                print(f\"Added {len(df_real)} real tweets\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Twitter API issue: {str(e)[:100]}...\")\n",
        "        print(\"Continuing with sample data only\")\n",
        "\n",
        "    print(\"\\nGenerating comprehensive sample dataset...\")\n",
        "    df_sample = collector.generate_realistic_sample_data(1200)\n",
        "    df_final = pd.concat([df_final, df_sample], ignore_index=True)\n",
        "\n",
        "    df_final['created_at'] = pd.to_datetime(df_final['created_at'])\n",
        "    df_final['hour'] = df_final['created_at'].dt.hour\n",
        "    df_final['day_of_week'] = df_final['created_at'].dt.day_name()\n",
        "    df_final['date'] = df_final['created_at'].dt.date\n",
        "    df_final['is_weekend'] = df_final['created_at'].dt.weekday >= 5\n",
        "\n",
        "    print(f\"\\n Final dataset ready!\")\n",
        "    print(f\"Total tweets: {len(df_final):,}\")\n",
        "    print(f\"Real tweets: {len(df_final[df_final['source'] == 'twitter_api']):,}\")\n",
        "    print(f\"Sample tweets: {len(df_final[df_final['source'] == 'sample_data']):,}\")\n",
        "    print(f\"Date range: {df_final['created_at'].min().date()} to {df_final['created_at'].max().date()}\")\n",
        "\n",
        "    return df_final, collector\n",
        "\n",
        "df_tweets, collector = initialize_data_collection()"
      ],
      "metadata": {
        "id": "yNBAgeuWfMAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis"
      ],
      "metadata": {
        "id": "-6Hh1nSsgG0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedSentimentAnalyzer:\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "        self.summary_stats = self.calculate_summary_stats()\n",
        "\n",
        "    def calculate_summary_stats(self):\n",
        "        \"\"\"Calculate comprehensive summary statistics\"\"\"\n",
        "        total_tweets = len(self.df)\n",
        "        sentiment_counts = self.df['sentiment'].value_counts()\n",
        "\n",
        "        return {\n",
        "            'total_tweets': total_tweets,\n",
        "            'unique_users': self.df['author_id'].nunique(),\n",
        "            'date_range': (self.df['created_at'].min(), self.df['created_at'].max()),\n",
        "            'positive_pct': (sentiment_counts.get('Positive', 0) / total_tweets) * 100,\n",
        "            'negative_pct': (sentiment_counts.get('Negative', 0) / total_tweets) * 100,\n",
        "            'neutral_pct': (sentiment_counts.get('Neutral', 0) / total_tweets) * 100,\n",
        "            'avg_polarity': self.df['polarity'].mean(),\n",
        "            'avg_subjectivity': self.df['subjectivity'].mean(),\n",
        "            'avg_confidence': self.df['confidence'].mean(),\n",
        "            'avg_word_count': self.df['word_count'].mean(),\n",
        "            'total_engagement': self.df['like_count'].sum() + self.df['retweet_count'].sum(),\n",
        "            'top_emotions': self.df['emotion'].value_counts().head().to_dict()\n",
        "        }\n",
        "\n",
        "    def get_time_analysis(self):\n",
        "        \"\"\"Comprehensive time-based analysis\"\"\"\n",
        "        hourly = self.df.groupby('hour').agg({\n",
        "            'polarity': ['mean', 'std', 'count'],\n",
        "            'subjectivity': 'mean',\n",
        "            'confidence': 'mean',\n",
        "            'like_count': 'sum'\n",
        "        }).round(3)\n",
        "\n",
        "        daily = self.df.groupby('day_of_week').agg({\n",
        "            'polarity': ['mean', 'std', 'count'],\n",
        "            'subjectivity': 'mean',\n",
        "            'confidence': 'mean'\n",
        "        }).round(3)\n",
        "\n",
        "        return hourly, daily\n",
        "\n",
        "    def get_emotion_analysis(self):\n",
        "        \"\"\"Analyze emotional patterns\"\"\"\n",
        "        emotion_sentiment = pd.crosstab(self.df['emotion'], self.df['sentiment'], normalize='index') * 100\n",
        "        emotion_by_hour = self.df.groupby(['hour', 'emotion']).size().unstack(fill_value=0)\n",
        "\n",
        "        return emotion_sentiment, emotion_by_hour\n",
        "\n",
        "    def get_engagement_analysis(self):\n",
        "        \"\"\"Analyze engagement patterns\"\"\"\n",
        "        engagement_by_sentiment = self.df.groupby('sentiment').agg({\n",
        "            'like_count': ['mean', 'sum'],\n",
        "            'retweet_count': ['mean', 'sum'],\n",
        "            'confidence': 'mean'\n",
        "        }).round(2)\n",
        "\n",
        "        return engagement_by_sentiment\n",
        "\n",
        "analyzer = EnhancedSentimentAnalyzer(df_tweets)\n",
        "summary = analyzer.summary_stats\n",
        "\n",
        "print(\"\\n MOOD of the World Analysis\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Dataset Overview:\")\n",
        "print(f\"   • Total Tweets: {summary['total_tweets']:,}\")\n",
        "print(f\"   • Unique Users: {summary['unique_users']:,}\")\n",
        "print(f\"   • Date Range: {summary['date_range'][0].date()} to {summary['date_range'][1].date()}\")\n",
        "print(f\"\\n Sentiment Distribution:\")\n",
        "print(f\"   • Positive: {summary['positive_pct']:.1f}%\")\n",
        "print(f\"   • Negative: {summary['negative_pct']:.1f}%\")\n",
        "print(f\"   • Neutral: {summary['neutral_pct']:.1f}%\")\n",
        "print(f\"\\n Quality Metrics:\")\n",
        "print(f\"   • Average Polarity: {summary['avg_polarity']:.3f}\")\n",
        "print(f\"   • Average Confidence: {summary['avg_confidence']:.3f}\")\n",
        "print(f\"   • Average Word Count: {summary['avg_word_count']:.1f}\")\n",
        "print(f\"\\n Engagement:\")\n",
        "print(f\"   • Total Likes + Retweets: {summary['total_engagement']:,}\")\n",
        "print(f\"\\n Top Emotions:\")\n",
        "for emotion, count in summary['top_emotions'].items():\n",
        "    print(f\"   • {emotion.title()}: {count:,}\")"
      ],
      "metadata": {
        "id": "jfAEAFcbgG73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standard Plotting Functions and Time Series"
      ],
      "metadata": {
        "id": "J-NNAAQegqqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StandardPlotter:\n",
        "    def __init__(self, df, analyzer):\n",
        "        self.df = df\n",
        "        self.analyzer = analyzer\n",
        "        # plt.style.use('default')  # Changed from 'seaborn-v0_8' which might not be available\n",
        "        plt.rcParams['figure.facecolor'] = 'white'\n",
        "        plt.rcParams['axes.facecolor'] = 'white'\n",
        "\n",
        "    def plot_sentiment_overview(self, figsize=(15, 10)):\n",
        "        \"\"\"Create comprehensive standard plots overview\"\"\"\n",
        "        fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
        "        fig.suptitle('Sentiment Analysis - Standard Plots', fontsize=16, fontweight='bold')\n",
        "\n",
        "        sentiment_counts = self.df['sentiment'].value_counts()\n",
        "        colors = ['#2E86AB', '#A23B72', '#F18F01']\n",
        "        wedges, texts, autotexts = axes[0, 0].pie(\n",
        "            sentiment_counts.values,\n",
        "            labels=sentiment_counts.index,\n",
        "            autopct='%1.1f%%',\n",
        "            colors=colors,\n",
        "            startangle=90,\n",
        "            textprops={'fontsize': 10}\n",
        "        )\n",
        "        axes[0, 0].set_title('Sentiment Distribution', fontweight='bold')\n",
        "\n",
        "        axes[0, 1].hist(self.df['polarity'], bins=30, color='#2E86AB', alpha=0.7, edgecolor='black')\n",
        "        mean_polarity = self.df['polarity'].mean()\n",
        "        axes[0, 1].axvline(mean_polarity, color='red', linestyle='--', linewidth=2,\n",
        "                          label=f'Mean: {mean_polarity:.3f}')\n",
        "        axes[0, 1].set_title('Polarity Distribution', fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Polarity Score')\n",
        "        axes[0, 1].set_ylabel('Frequency')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        hourly_sentiment = self.df.groupby(['hour', 'sentiment']).size().unstack(fill_value=0)\n",
        "        hourly_sentiment.plot(kind='bar', ax=axes[0, 2], color=colors, width=0.8)\n",
        "        axes[0, 2].set_title('Sentiment by Hour of Day', fontweight='bold')\n",
        "        axes[0, 2].set_xlabel('Hour')\n",
        "        axes[0, 2].set_ylabel('Tweet Count')\n",
        "        axes[0, 2].legend(title='Sentiment', loc='upper right')\n",
        "        axes[0, 2].tick_params(axis='x', rotation=45)\n",
        "        axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        scatter = axes[1, 0].scatter(\n",
        "            self.df['subjectivity'],\n",
        "            self.df['polarity'],\n",
        "            c=self.df['confidence'],\n",
        "            cmap='viridis',\n",
        "            alpha=0.6,\n",
        "            s=30\n",
        "        )\n",
        "        axes[1, 0].set_title('Polarity vs Subjectivity', fontweight='bold')\n",
        "        axes[1, 0].set_xlabel('Subjectivity')\n",
        "        axes[1, 0].set_ylabel('Polarity')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "        cbar = plt.colorbar(scatter, ax=axes[1, 0])\n",
        "        cbar.set_label('Confidence', rotation=270, labelpad=15)\n",
        "\n",
        "        emotion_counts = self.df['emotion'].value_counts().head(8)\n",
        "        bars = axes[1, 1].bar(\n",
        "            range(len(emotion_counts)),\n",
        "            emotion_counts.values,\n",
        "            color=plt.cm.Set3(np.linspace(0, 1, len(emotion_counts)))\n",
        "        )\n",
        "        axes[1, 1].set_title('Top Emotions', fontweight='bold')\n",
        "        axes[1, 1].set_xlabel('Emotion')\n",
        "        axes[1, 1].set_ylabel('Count')\n",
        "        axes[1, 1].set_xticks(range(len(emotion_counts)))\n",
        "        axes[1, 1].set_xticklabels(emotion_counts.index, rotation=45, ha='right')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        for bar, value in zip(bars, emotion_counts.values):\n",
        "            axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(emotion_counts.values)*0.01,\n",
        "                           str(value), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        daily_polarity = self.df.groupby(self.df['created_at'].dt.date)['polarity'].mean()\n",
        "        axes[1, 2].plot(\n",
        "            daily_polarity.index,\n",
        "            daily_polarity.values,\n",
        "            marker='o',\n",
        "            linewidth=2,\n",
        "            markersize=4,\n",
        "            color='#2E86AB'\n",
        "        )\n",
        "        axes[1, 2].set_title('Daily Sentiment Trend', fontweight='bold')\n",
        "        axes[1, 2].set_xlabel('Date')\n",
        "        axes[1, 2].set_ylabel('Average Polarity')\n",
        "        axes[1, 2].tick_params(axis='x', rotation=45)\n",
        "        axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        if len(daily_polarity) > 1:\n",
        "            z = np.polyfit(range(len(daily_polarity)), daily_polarity.values, 1)\n",
        "            p = np.poly1d(z)\n",
        "            axes[1, 2].plot(daily_polarity.index, p(range(len(daily_polarity))),\n",
        "                           \"r--\", alpha=0.8, linewidth=1, label='Trend')\n",
        "            axes[1, 2].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(top=0.93)\n",
        "        plt.show()\n",
        "        plt.draw()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def plot_time_analysis(self, figsize=(14, 10)):\n",
        "        \"\"\"Time-based analysis plots\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
        "        fig.suptitle('Time-Based Sentiment Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "        hourly_sentiment = self.df.groupby(['hour', 'sentiment']).size().unstack(fill_value=0)\n",
        "        hourly_pct = hourly_sentiment.div(hourly_sentiment.sum(axis=1), axis=0) * 100\n",
        "\n",
        "        im = axes[0, 0].imshow(hourly_pct.T.values, cmap='RdYlBu_r', aspect='auto', interpolation='nearest')\n",
        "        axes[0, 0].set_title('Hourly Sentiment Distribution (%)', fontweight='bold')\n",
        "        axes[0, 0].set_xlabel('Hour of Day')\n",
        "        axes[0, 0].set_ylabel('Sentiment')\n",
        "        axes[0, 0].set_xticks(range(0, 24, 2))\n",
        "        axes[0, 0].set_xticklabels(range(0, 24, 2))\n",
        "        axes[0, 0].set_yticks(range(len(hourly_pct.columns)))\n",
        "        axes[0, 0].set_yticklabels(hourly_pct.columns)\n",
        "\n",
        "        cbar = plt.colorbar(im, ax=axes[0, 0])\n",
        "        cbar.set_label('Percentage', rotation=270, labelpad=15)\n",
        "\n",
        "        for i in range(len(hourly_pct.columns)):\n",
        "            for j in range(len(hourly_pct.index)):\n",
        "                if hourly_pct.T.iloc[i, j] > 0:\n",
        "                    text = axes[0, 0].text(j, i, f'{hourly_pct.T.iloc[i, j]:.0f}%',\n",
        "                                         ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
        "\n",
        "        weekend_sentiment = self.df.groupby(['is_weekend', 'sentiment']).size().unstack(fill_value=0)\n",
        "        weekend_sentiment.plot(kind='bar', ax=axes[0, 1],\n",
        "                             color=['#2E86AB', '#A23B72', '#F18F01'],\n",
        "                             width=0.7)\n",
        "        axes[0, 1].set_title('Weekend vs Weekday Sentiment', fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Day Type')\n",
        "        axes[0, 1].set_xticklabels(['Weekday', 'Weekend'], rotation=0)\n",
        "        axes[0, 1].legend(title='Sentiment', loc='upper right')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        for container in axes[0, 1].containers:\n",
        "            axes[0, 1].bar_label(container, label_type='edge', fontsize=9)\n",
        "\n",
        "        hourly_activity = self.df.groupby('hour').size()\n",
        "        bars = axes[1, 0].bar(hourly_activity.index, hourly_activity.values,\n",
        "                             color='#2E86AB', alpha=0.7, edgecolor='black')\n",
        "        axes[1, 0].set_title('Tweet Activity by Hour', fontweight='bold')\n",
        "        axes[1, 0].set_xlabel('Hour of Day')\n",
        "        axes[1, 0].set_ylabel('Tweet Count')\n",
        "        axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "        peak_hour = hourly_activity.idxmax()\n",
        "        axes[1, 0].bar(peak_hour, hourly_activity[peak_hour],\n",
        "                      color='#F18F01', alpha=0.9, edgecolor='black')\n",
        "        axes[1, 0].text(peak_hour, hourly_activity[peak_hour] + max(hourly_activity)*0.02,\n",
        "                       'Peak', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        daily_emotions = self.df.groupby([self.df['created_at'].dt.date, 'emotion']).size().unstack(fill_value=0)\n",
        "        top_emotions = self.df['emotion'].value_counts().head(5).index\n",
        "\n",
        "        colors_emotion = plt.cm.Set1(np.linspace(0, 1, len(top_emotions)))\n",
        "\n",
        "        for i, emotion in enumerate(top_emotions):\n",
        "            if emotion in daily_emotions.columns:\n",
        "                axes[1, 1].plot(daily_emotions.index, daily_emotions[emotion],\n",
        "                               marker='o', label=emotion.title(), linewidth=2,\n",
        "                               markersize=4, color=colors_emotion[i])\n",
        "\n",
        "        axes[1, 1].set_title('Daily Emotion Trends', fontweight='bold')\n",
        "        axes[1, 1].set_xlabel('Date')\n",
        "        axes[1, 1].set_ylabel('Count')\n",
        "        axes[1, 1].legend(loc='upper right')\n",
        "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(top=0.93)\n",
        "\n",
        "        plt.show()\n",
        "        plt.draw()\n",
        "\n",
        "        return fig\n",
        "\n",
        "standard_plotter = StandardPlotter(df_tweets, analyzer)\n",
        "\n",
        "print(\"Standard Visualizations...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\n Sentiment Overview... \\n\")\n",
        "overview_fig = standard_plotter.plot_sentiment_overview()\n",
        "\n",
        "print(\"\\n Time Analysis...\\n\")\n",
        "time_fig = standard_plotter.plot_time_analysis()\n",
        "\n",
        "print(f\"\\n Quick Stats:\\n\")\n",
        "print(f\"   • Most active hour: {df_tweets.groupby('hour').size().idxmax()}:00\")\n",
        "print(f\"   • Most positive hour: {df_tweets.groupby('hour')['polarity'].mean().idxmax()}:00\")\n",
        "print(f\"   • Weekend mood: {df_tweets[df_tweets['is_weekend']]['polarity'].mean():.3f}\")\n",
        "print(f\"   • Weekday mood: {df_tweets[~df_tweets['is_weekend']]['polarity'].mean():.3f}\")\n",
        "print(f\"   • Top emotion: {df_tweets['emotion'].mode().iloc[0].title()}\")"
      ],
      "metadata": {
        "id": "iRY4TI6pgqyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# in this version the application uses free API with rate limit to retrive the data also a sample data of 1200 is used for demonstration. So the program runs without Online API also\n",
        "\n",
        "## Expectation on upcoming version continuation\n",
        "* More Detailed and interactive Graph\n",
        "* Advanced Analytics and Insights\n",
        "* And Many more in future"
      ],
      "metadata": {
        "id": "i0yC--fzc4QZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Html Report"
      ],
      "metadata": {
        "id": "p6VOTi4R31VD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sample_data(n_samples=1000):\n",
        "    emotions = ['joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'trust', 'anticipation']\n",
        "    sentiments = ['Positive', 'Negative', 'Neutral']\n",
        "    data = []\n",
        "    base_date = datetime.now() - timedelta(days=7)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        random_date = base_date + timedelta(\n",
        "            days=random.randint(0, 6),\n",
        "            hours=random.randint(0, 23),\n",
        "            minutes=random.randint(0, 59)\n",
        "        )\n",
        "\n",
        "        polarity = random.uniform(-1, 1)\n",
        "        subjectivity = random.uniform(0, 1)\n",
        "        confidence = random.uniform(0.5, 1.0)\n",
        "        if polarity > 0.1:\n",
        "            sentiment = 'Positive'\n",
        "        elif polarity < -0.1:\n",
        "            sentiment = 'Negative'\n",
        "        else:\n",
        "            sentiment = 'Neutral'\n",
        "\n",
        "        sample_texts = [\n",
        "            \"Having a great day today! #happy #blessed\",\n",
        "            \"Feeling frustrated with the current situation\",\n",
        "            \"Just another ordinary day at work\",\n",
        "            \"Excited about the upcoming weekend plans\",\n",
        "            \"Weather is perfect for a walk in the park\",\n",
        "            \"Technology is amazing these days\",\n",
        "            \"Missing the good old times\",\n",
        "            \"Looking forward to new opportunities\"\n",
        "        ]\n",
        "\n",
        "        data.append({\n",
        "            'text': random.choice(sample_texts),\n",
        "            'created_at': random_date,\n",
        "            'hour': random_date.hour,\n",
        "            'sentiment': sentiment,\n",
        "            'emotion': random.choice(emotions),\n",
        "            'polarity': polarity,\n",
        "            'subjectivity': subjectivity,\n",
        "            'confidence': confidence,\n",
        "            'like_count': random.randint(0, 100),\n",
        "            'retweet_count': random.randint(0, 50)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "print(\"Generating data...\")\n",
        "df_tweets = generate_sample_data(1000)\n",
        "print(f\"Generated {len(df_tweets)} tweets\")\n",
        "\n",
        "class InteractivePlotter:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def create_sentiment_dashboard(self):\n",
        "        \"\"\"Interactive Dashboard\"\"\"\n",
        "        print(\"Sentiment Dashboard...\")\n",
        "\n",
        "        fig = make_subplots(\n",
        "            rows=3, cols=2,\n",
        "            subplot_titles=('Sentiment Distribution', 'Hourly Sentiment Patterns',\n",
        "                          'Emotion Analysis', 'Engagement vs Sentiment',\n",
        "                          'Polarity vs Subjectivity', 'Daily Trend'),\n",
        "            specs=[[{\"type\": \"pie\"}, {\"type\": \"bar\"}],\n",
        "                   [{\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
        "                   [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]]\n",
        "        )\n",
        "        sentiment_counts = self.df['sentiment'].value_counts()\n",
        "        fig.add_trace(go.Pie(\n",
        "            labels=sentiment_counts.index,\n",
        "            values=sentiment_counts.values,\n",
        "            marker_colors=['#2E86AB', '#A23B72', '#F18F01'],\n",
        "            hole=0.3,\n",
        "            name=\"Sentiment\"\n",
        "        ), row=1, col=1)\n",
        "\n",
        "        hourly_sentiment = self.df.groupby(['hour', 'sentiment']).size().unstack(fill_value=0)\n",
        "        colors_sentiment = {'Positive': '#2E86AB', 'Negative': '#A23B72', 'Neutral': '#F18F01'}\n",
        "        for sentiment in hourly_sentiment.columns:\n",
        "            color = colors_sentiment.get(sentiment, '#666666')\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=hourly_sentiment.index,\n",
        "                y=hourly_sentiment[sentiment],\n",
        "                name=f'Hourly {sentiment}',\n",
        "                marker_color=color,\n",
        "                showlegend=False\n",
        "            ), row=1, col=2)\n",
        "\n",
        "        emotion_counts = self.df['emotion'].value_counts().head(8)\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=emotion_counts.index,\n",
        "            y=emotion_counts.values,\n",
        "            marker_color=px.colors.qualitative.Set3[:len(emotion_counts)],\n",
        "            name=\"Emotions\",\n",
        "            showlegend=False\n",
        "        ), row=2, col=1)\n",
        "\n",
        "        engagement_sentiment = self.df.groupby('sentiment').agg({\n",
        "            'like_count': 'mean',\n",
        "            'retweet_count': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=engagement_sentiment['like_count'],\n",
        "            y=engagement_sentiment['retweet_count'],\n",
        "            mode='markers+text',\n",
        "            text=engagement_sentiment['sentiment'],\n",
        "            textposition='top center',\n",
        "            marker=dict(\n",
        "                size=20,\n",
        "                color=['#2E86AB', '#A23B72', '#F18F01'][:len(engagement_sentiment)]\n",
        "            ),\n",
        "            name=\"Engagement\",\n",
        "            showlegend=False\n",
        "        ), row=2, col=2)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=self.df['subjectivity'],\n",
        "            y=self.df['polarity'],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                color=self.df['confidence'],\n",
        "                colorscale='viridis',\n",
        "                size=4,\n",
        "                opacity=0.6,\n",
        "                showscale=True,\n",
        "                colorbar=dict(\n",
        "                    title=\"Confidence\",\n",
        "                    x=0.45,\n",
        "                    len=0.3\n",
        "                )\n",
        "            ),\n",
        "            name=\"Polarity vs Subjectivity\",\n",
        "            showlegend=False\n",
        "        ), row=3, col=1)\n",
        "\n",
        "        daily_polarity = self.df.groupby(self.df['created_at'].dt.date)['polarity'].mean()\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=daily_polarity.index,\n",
        "            y=daily_polarity.values,\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='#2E86AB', width=3),\n",
        "            marker=dict(size=8),\n",
        "            name=\"Daily Trend\",\n",
        "            showlegend=False\n",
        "        ), row=3, col=2)\n",
        "\n",
        "        fig.update_layout(\n",
        "            height=1200,\n",
        "            title_text=\"Mood of the World Analysis Dashboard\",\n",
        "            title_font_size=20,\n",
        "            title_x=0.5,\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_emotion_heatmap(self):\n",
        "        \"\"\"emotion-time heatmap\"\"\"\n",
        "        print(\"Emotion Heatmap...\")\n",
        "\n",
        "        emotion_hour = self.df.groupby(['hour', 'emotion']).size().unstack(fill_value=0)\n",
        "\n",
        "        top_emotions = self.df['emotion'].value_counts().head(8).index\n",
        "        emotion_hour_filtered = emotion_hour[top_emotions]\n",
        "\n",
        "        fig = go.Figure(data=go.Heatmap(\n",
        "            z=emotion_hour_filtered.T.values,\n",
        "            x=emotion_hour_filtered.index,\n",
        "            y=emotion_hour_filtered.columns,\n",
        "            colorscale='viridis',\n",
        "            hoverongaps=False,\n",
        "            hovertemplate='Hour: %{x}<br>Emotion: %{y}<br>Count: %{z}<extra></extra>'\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='Emotion Patterns Throughout the Day',\n",
        "            title_font_size=16,\n",
        "            title_x=0.5,\n",
        "            xaxis_title='Hour of Day',\n",
        "            yaxis_title='Emotion',\n",
        "            height=600,\n",
        "            width=800\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_word_frequency_chart(self):\n",
        "        \"\"\"Create word frequency visualization\"\"\"\n",
        "        print(\"word frequency chart...\")\n",
        "\n",
        "        all_text = ' '.join(self.df['text'].astype(str))\n",
        "\n",
        "        words = re.findall(r'\\b[a-zA-Z]{3,}\\b', all_text.lower())\n",
        "        stop_words = {\n",
        "            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',\n",
        "            'i', 'you', 'he', 'she', 'it', 'we', 'they', 'this', 'that', 'is', 'are', 'was', 'were',\n",
        "            'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should',\n",
        "            'may', 'might', 'can', 'cant', 'dont', 'wont', 'im', 'youre', 'hes', 'shes', 'its', 'were',\n",
        "            'theyre', 'today', 'just', 'get', 'got', 'going', 'go', 'like', 'really', 'know', 'time',\n",
        "            'day', 'way', 'think', 'feel', 'feeling', 'good', 'great', 'bad', 'new', 'one', 'two'\n",
        "        }\n",
        "\n",
        "        filtered_words = [word for word in words if word not in stop_words and len(word) > 3]\n",
        "        word_freq = Counter(filtered_words).most_common(25)\n",
        "\n",
        "        if word_freq:\n",
        "            words_list, counts_list = zip(*word_freq)\n",
        "        else:\n",
        "            words_list, counts_list = ['sample', 'words', 'example'], [10, 8, 5]\n",
        "\n",
        "        fig = go.Figure(data=go.Bar(\n",
        "            x=list(words_list),\n",
        "            y=list(counts_list),\n",
        "            marker_color=px.colors.sequential.Viridis,\n",
        "            hovertemplate='Word: %{x}<br>Frequency: %{y}<extra></extra>'\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='Most Frequent Words in Tweets',\n",
        "            title_font_size=16,\n",
        "            title_x=0.5,\n",
        "            xaxis_title='Words',\n",
        "            yaxis_title='Frequency',\n",
        "            height=500,\n",
        "            width=800,\n",
        "            xaxis_tickangle=-45\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_time_series_analysis(self):\n",
        "        \"\"\"Create detailed time series analysis\"\"\"\n",
        "        print(\"time series analysis...\")\n",
        "\n",
        "        # Hourly sentiment trends\n",
        "        hourly_data = self.df.groupby('hour').agg({\n",
        "            'polarity': 'mean',\n",
        "            'subjectivity': 'mean',\n",
        "            'confidence': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        fig = go.Figure()\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=hourly_data['hour'],\n",
        "            y=hourly_data['polarity'],\n",
        "            mode='lines+markers',\n",
        "            name='Polarity',\n",
        "            line=dict(color='#2E86AB', width=3),\n",
        "            marker=dict(size=8)\n",
        "        ))\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=hourly_data['hour'],\n",
        "            y=hourly_data['subjectivity'],\n",
        "            mode='lines+markers',\n",
        "            name='Subjectivity',\n",
        "            line=dict(color='#A23B72', width=3),\n",
        "            marker=dict(size=8),\n",
        "            yaxis='y2'\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='Hourly Sentiment Patterns',\n",
        "            title_font_size=16,\n",
        "            title_x=0.5,\n",
        "            xaxis_title='Hour of Day',\n",
        "            yaxis_title='Polarity Score',\n",
        "            yaxis2=dict(\n",
        "                title='Subjectivity Score',\n",
        "                overlaying='y',\n",
        "                side='right'\n",
        "            ),\n",
        "            height=500,\n",
        "            width=800,\n",
        "            hovermode='x unified'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "interactive_plotter = InteractivePlotter(df_tweets)\n",
        "\n",
        "print(\"Interactive Visualizations...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Display data info\n",
        "print(f\"\\n Dataset Info:\")\n",
        "print(f\"Total tweets: {len(df_tweets)}\")\n",
        "print(f\"Date range: {df_tweets['created_at'].min()} to {df_tweets['created_at'].max()}\")\n",
        "print(f\"Sentiment distribution:\\n{df_tweets['sentiment'].value_counts()}\")\n",
        "\n",
        "print(\"\\n1.Sentiment Dashboard...\")\n",
        "dashboard_fig = interactive_plotter.create_sentiment_dashboard()\n",
        "dashboard_fig.show()\n",
        "\n",
        "print(\"\\n2. Emotion Heatmap...\")\n",
        "emotion_heatmap = interactive_plotter.create_emotion_heatmap()\n",
        "emotion_heatmap.show()\n",
        "\n",
        "print(\"\\n3. Word Frequency Analysis...\")\n",
        "word_freq_fig = interactive_plotter.create_word_frequency_chart()\n",
        "word_freq_fig.show()\n",
        "\n",
        "print(\"\\n4. Time Series Analysis...\")\n",
        "time_series_fig = interactive_plotter.create_time_series_analysis()\n",
        "time_series_fig.show()\n",
        "dashboard_fig.write_html(\"sentiment_dashboard.html\")\n",
        "emotion_heatmap.write_html(\"emotion_heatmap.html\")\n",
        "word_freq_fig.write_html(\"word_frequency.html\")\n",
        "time_series_fig.write_html(\"time_series.html\")\n",
        "print(\"HTML files saved successfully!\")"
      ],
      "metadata": {
        "id": "RgmBA15i31gC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}